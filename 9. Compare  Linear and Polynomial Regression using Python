import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score

# Generate Non-Linear Data: X and y (Quadratic Relationship)
np.random.seed(42)
X = np.linspace(0, 10, 50).reshape(-1, 1)
y = 3 * X**2 + 2 * X + np.random.randn(50, 1) * 10  # Quadratic function with noise

# Split Data into Training and Testing Sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 1️⃣ Linear Regression
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)
y_pred_linear = lr_model.predict(X_test)

# 2️⃣ Polynomial Regression (Degree 2)
poly = PolynomialFeatures(degree=2)
X_train_poly = poly.fit_transform(X_train)
X_test_poly = poly.transform(X_test)

poly_model = LinearRegression()
poly_model.fit(X_train_poly, y_train)
y_pred_poly = poly_model.predict(X_test_poly)

# Evaluate Models
r2_linear = r2_score(y_test, y_pred_linear)
r2_poly = r2_score(y_test, y_pred_poly)

print(f"Linear Regression R² Score: {r2_linear:.3f}")
print(f"Polynomial Regression R² Score: {r2_poly:.3f}")

# Plot Results
plt.figure(figsize=(8, 5))
sns.scatterplot(x=X.flatten(), y=y.flatten(), label="Actual Data", color='blue')

# Plot Linear Regression Line
plt.plot(X_test.flatten(), y_pred_linear.flatten(), label="Linear Regression", color='red')

# Plot Polynomial Regression Curve
X_sorted = np.sort(X_test, axis=0)  # Sort for smooth plotting
y_pred_poly_sorted = poly_model.predict(poly.transform(X_sorted))
plt.plot(X_sorted.flatten(), y_pred_poly_sorted.flatten(), label="Polynomial Regression", color='green')

plt.xlabel("X Values")
plt.ylabel("Y Values")
plt.title("Linear vs. Polynomial Regression")
plt.legend()
plt.show()
